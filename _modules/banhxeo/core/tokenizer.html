

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>banhxeo.core.tokenizer &mdash; banhxeo  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            banhxeo
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/modules.html">banhxeo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">banhxeo</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
          <li class="breadcrumb-item"><a href="../../banhxeo.html">banhxeo</a></li>
      <li class="breadcrumb-item active">banhxeo.core.tokenizer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for banhxeo.core.tokenizer</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABCMeta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">model_validator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Self</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">banhxeo.utils.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">DEFAULT_LOGGER</span>


<div class="viewcode-block" id="TokenizerConfig">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.TokenizerConfig">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TokenizerConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for tokenizers.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        add_special_tokens: Whether to add special tokens like BOS/EOS.</span>
<span class="sd">        max_length: Maximum sequence length. If specified, truncation or padding</span>
<span class="sd">            might be applied.</span>
<span class="sd">        truncation: Whether to truncate sequences longer than `max_length`.</span>
<span class="sd">        padding: Strategy for padding. Can be:</span>
<span class="sd">            - False or &quot;do_not_pad&quot;: No padding.</span>
<span class="sd">            - True or &quot;max_length&quot;: Pad to `max_length`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">add_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">truncation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;do_not_pad&quot;</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">False</span>  <span class="c1"># False = &quot;do_not_pad&quot;, True = &quot;max_length&quot;</span>
    <span class="p">)</span>

<div class="viewcode-block" id="TokenizerConfig.check_padding">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.TokenizerConfig.check_padding">[docs]</a>
    <span class="nd">@model_validator</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;after&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">check_padding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validates padding configuration against max_length.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;max_length&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If padding is max_length, you must provide value for max_length parameter&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="s2">&quot;max_length&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="k">else</span> <span class="s2">&quot;do_not_pad&quot;</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="Tokenizer">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Tokenizer</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract Base Class for all tokenizers.</span>

<span class="sd">    Defines the core interface for tokenization, encoding, and managing</span>
<span class="sd">    tokenizer-specific data like pre-trained models or vocabularies.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_or_texts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenizes a single text or a list of texts.</span>

<span class="sd">        Args:</span>
<span class="sd">            text_or_texts: A single string or a list of strings to tokenize.</span>
<span class="sd">            **kwargs: Additional arguments passed to the `tokenize` method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            If input is a single string, returns a list of tokens.</span>
<span class="sd">            If input is a list of strings, returns a list of lists of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text_or_texts</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text_or_texts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text_or_texts</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">text_or_texts</span><span class="p">]</span>

<div class="viewcode-block" id="Tokenizer.tokenize">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.tokenize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenizes a single string into a list of tokens.</span>

<span class="sd">        This method should be implemented by all concrete tokenizer subclasses.</span>
<span class="sd">        The base implementation provides a simple regex-based tokenizer as a fallback.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: The input string to tokenize.</span>
<span class="sd">            **kwargs: Subclass-specific tokenization arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of string tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Default is regrex tokenizer</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

        <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;\w+(?:&#39;\w+)?|[^\w\s]&quot;</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span></div>


<div class="viewcode-block" id="Tokenizer.encode">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.encode">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">vocab</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>  <span class="c1"># type: ignore  # noqa: F821</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">TokenizerConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a text string into a dictionary of encoded features.</span>

<span class="sd">        This base implementation handles tokenization, addition of special tokens,</span>
<span class="sd">        truncation, and padding based on the provided configuration.</span>
<span class="sd">        Subclasses can override this for more specialized encoding logic.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: The input string to encode.</span>
<span class="sd">            vocab: The vocabulary instance for mapping tokens to IDs.</span>
<span class="sd">            config: TokenizerConfig object specifying encoding parameters.</span>
<span class="sd">            **kwargs: Additional arguments, potentially passed to the `tokenize` method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary containing:</span>
<span class="sd">                - &quot;input_ids&quot;: List of token IDs.</span>
<span class="sd">                - &quot;attention_mask&quot;: List of 0s and 1s indicating padding.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If padding is &#39;max_length&#39; but `config.max_length` is not set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Tokenize text</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># kwargs might be passed to tokenize</span>

        <span class="c1"># Add special tokens</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">:</span>
            <span class="n">bos_tokens</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">bos_toks</span>
            <span class="n">sep_tokens</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">sep_toks</span>

            <span class="c1"># Truncate with special tokens</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">truncation</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">max_text_tokens</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_tokens</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sep_tokens</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">max_text_tokens</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">DEFAULT_LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;max_length (</span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="si">}</span><span class="s2">) is too small for special tokens. &quot;</span>
                        <span class="s2">&quot;Resulting sequence might be only special tokens or empty.&quot;</span>
                    <span class="p">)</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">max_text_tokens</span><span class="p">]</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="n">bos_tokens</span> <span class="o">+</span> <span class="n">tokens</span> <span class="o">+</span> <span class="n">sep_tokens</span>
        <span class="c1"># Truncate without special tokens</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">truncation</span>
            <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span>
        <span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">]</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">tokens_to_ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span>
            <span class="n">pad_len</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="k">if</span> <span class="n">pad_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_ids</span> <span class="o">+=</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span>
                <span class="n">attention_mask</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">pad_len</span> <span class="o">&lt;</span> <span class="mi">0</span>
            <span class="p">):</span>  <span class="c1"># Sequence is longer than max_length after adding special tokens</span>
                <span class="c1"># This implies truncation didn&#39;t fully reduce it, or max_length is very small</span>
                <span class="n">DEFAULT_LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Sequence length (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="si">}</span><span class="s2">) is greater than max_length (</span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="si">}</span><span class="s2">) &quot;</span>
                    <span class="s2">&quot;even after potential truncation. Output will be truncated to max_length.&quot;</span>
                <span class="p">)</span>
            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span>
            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>

        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="Tokenizer.batch_encode">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.batch_encode">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">vocab</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>  <span class="c1"># noqa: F821 # type: ignore</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">TokenizerConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Encodes a batch of text strings.</span>

<span class="sd">        Args:</span>
<span class="sd">            texts: A list of strings to encode.</span>
<span class="sd">            vocab: The vocabulary instance.</span>
<span class="sd">            config: TokenizerConfig object.</span>
<span class="sd">            **kwargs: Additional arguments for the `encode` method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of dictionaries, where each dictionary is the output of `encode`</span>
<span class="sd">            for the corresponding text.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span></div>


<div class="viewcode-block" id="Tokenizer.train_from_iterator">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.train_from_iterator">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_from_iterator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">iterator</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">min_frequency</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">special_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;bos&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;eos&gt;&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Trains the tokenizer from an iterator of texts.</span>

<span class="sd">        This is primarily for tokenizers that learn a vocabulary or merges,</span>
<span class="sd">        such as BPE or WordPiece. Simpler tokenizers might implement this</span>
<span class="sd">        as a no-operation.</span>

<span class="sd">        Args:</span>
<span class="sd">            iterator: An iterable yielding text strings.</span>
<span class="sd">            vocab_size: The desired vocabulary size.</span>
<span class="sd">            min_frequency: The minimum frequency for a token to be included.</span>
<span class="sd">            special_tokens: A list of special tokens to include.</span>
<span class="sd">            **kwargs: Tokenizer-specific training arguments.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If the tokenizer does not support training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support training from an iterator.&quot;</span>
        <span class="p">)</span></div>


    <span class="c1"># --- Saving and Loading (Essential for trained/complex tokenizers) ---</span>

<div class="viewcode-block" id="Tokenizer.save_pretrained">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.save_pretrained">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves the tokenizer&#39;s state to a directory.</span>

<span class="sd">        This should save any learned vocabulary, merges, or configuration</span>
<span class="sd">        necessary to reload the tokenizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            save_directory: Path to the directory where the tokenizer will be saved.</span>
<span class="sd">            **kwargs: Additional saving arguments.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If saving is not implemented.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support save_pretrained.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Tokenizer.from_pretrained">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.Tokenizer.from_pretrained">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">load_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Tokenizer&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads a tokenizer from a previously saved directory.</span>

<span class="sd">        Args:</span>
<span class="sd">            load_directory: Path to the directory from which to load.</span>
<span class="sd">            **kwargs: Additional loading arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An instance of the tokenizer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If loading is not implemented.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support from_pretrained.&quot;</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="NLTKTokenizer">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.NLTKTokenizer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NLTKTokenizer</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A tokenizer that uses NLTK&#39;s TreebankWordTokenizer.</span>

<span class="sd">    Falls back to a regex-based tokenizer if NLTK is not installed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="NLTKTokenizer.tokenize">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.NLTKTokenizer.tokenize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenizes text using NLTK&#39;s TreebankWordTokenizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: The input string.</span>
<span class="sd">            **kwargs: Ignored (NLTK tokenizer doesn&#39;t take extra args here).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize.treebank</span><span class="w"> </span><span class="kn">import</span> <span class="n">TreebankWordTokenizer</span>

            <span class="n">t</span> <span class="o">=</span> <span class="n">TreebankWordTokenizer</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">DEFAULT_LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;NLTK not found. Falling back to regex-based tokenizer. &quot;</span>
                <span class="s2">&quot;Install NLTK for TreebankWordTokenizer: `pip install nltk`&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="NLTKTokenizer.detokenize">
<a class="viewcode-back" href="../../../api/banhxeo.core.tokenizer.html#banhxeo.core.NLTKTokenizer.detokenize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Detokenizes a list of tokens using NLTK&#39;s TreebankWordDetokenizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens: A list of string tokens.</span>
<span class="sd">            **kwargs: Ignored.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The detokenized string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize.treebank</span><span class="w"> </span><span class="kn">import</span> <span class="n">TreebankWordDetokenizer</span>

            <span class="n">detokenizer</span> <span class="o">=</span> <span class="n">TreebankWordDetokenizer</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">detokenizer</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">DEFAULT_LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;NLTK not found. Falling back to space-joining detokenizer. &quot;</span>
                <span class="s2">&quot;Install NLTK for TreebankWordDetokenizer: `pip install nltk`&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Le Nguyen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>