Search.setIndex({"alltitles": {"API References": [[48, null]], "Dependencies": [[49, "dependencies"]], "Getting Started": [[48, null]], "Indices and tables": [[48, "indices-and-tables"]], "Installation": [[49, null]], "Philosophy": [[48, "philosophy"]], "Submodules": [[2, "submodules"], [5, "submodules"], [13, "submodules"], [17, "submodules"], [23, "submodules"], [25, "submodules"], [32, "submodules"], [35, "submodules"], [38, "submodules"], [40, "submodules"], [44, "submodules"]], "Subpackages": [[0, "subpackages"], [1, "subpackages"], [2, "subpackages"], [13, "subpackages"], [23, "subpackages"], [32, "subpackages"]], "Welcome to Banhxeo\u2019s Documentation!": [[48, null]], "banhxeo": [[47, null]], "banhxeo package": [[0, null]], "banhxeo.core package": [[1, null]], "banhxeo.core.tokenizer package": [[2, null]], "banhxeo.core.tokenizer.config module": [[3, null]], "banhxeo.core.tokenizer.decoder package": [[4, null]], "banhxeo.core.tokenizer.model package": [[5, null]], "banhxeo.core.tokenizer.model.bpe module": [[6, null]], "banhxeo.core.tokenizer.model.word module": [[7, null]], "banhxeo.core.tokenizer.normalizers package": [[8, null]], "banhxeo.core.tokenizer.post_processor package": [[9, null]], "banhxeo.core.tokenizer.pre_tokenizer package": [[10, null]], "banhxeo.core.tokenizer.presets module": [[11, null]], "banhxeo.core.vocabulary module": [[12, null]], "banhxeo.data package": [[13, null]], "banhxeo.data.array module": [[14, null]], "banhxeo.data.base module": [[15, null]], "banhxeo.data.config module": [[16, null]], "banhxeo.data.dataset package": [[17, null]], "banhxeo.data.dataset.amazon_review module": [[18, null]], "banhxeo.data.dataset.imdb module": [[19, null]], "banhxeo.data.loader module": [[20, null]], "banhxeo.data.torch module": [[21, null]], "banhxeo.data.transforms module": [[22, null]], "banhxeo.model package": [[23, null]], "banhxeo.model.base module": [[24, null]], "banhxeo.model.classic package": [[25, null]], "banhxeo.model.classic.gru module": [[26, null]], "banhxeo.model.classic.lstm module": [[27, null]], "banhxeo.model.classic.mlp module": [[28, null]], "banhxeo.model.classic.rnn module": [[29, null]], "banhxeo.model.classic.word2vec module": [[30, null]], "banhxeo.model.config module": [[31, null]], "banhxeo.model.llm package": [[32, null]], "banhxeo.model.llm.config module": [[33, null]], "banhxeo.model.llm.gpt2 module": [[34, null]], "banhxeo.model.llm.layers package": [[35, null]], "banhxeo.model.llm.layers.layer_norm module": [[36, null]], "banhxeo.model.neural module": [[37, null]], "banhxeo.model.old package": [[38, null]], "banhxeo.model.old.n_gram module": [[39, null]], "banhxeo.train package": [[40, null]], "banhxeo.train.callbacks module": [[41, null]], "banhxeo.train.config module": [[42, null]], "banhxeo.train.trainer module": [[43, null]], "banhxeo.utils package": [[44, null]], "banhxeo.utils.file module": [[45, null]], "banhxeo.utils.logging module": [[46, null]]}, "docnames": ["api/banhxeo", "api/banhxeo.core", "api/banhxeo.core.tokenizer", "api/banhxeo.core.tokenizer.config", "api/banhxeo.core.tokenizer.decoder", "api/banhxeo.core.tokenizer.model", "api/banhxeo.core.tokenizer.model.bpe", "api/banhxeo.core.tokenizer.model.word", "api/banhxeo.core.tokenizer.normalizers", "api/banhxeo.core.tokenizer.post_processor", "api/banhxeo.core.tokenizer.pre_tokenizer", "api/banhxeo.core.tokenizer.presets", "api/banhxeo.core.vocabulary", "api/banhxeo.data", "api/banhxeo.data.array", "api/banhxeo.data.base", "api/banhxeo.data.config", "api/banhxeo.data.dataset", "api/banhxeo.data.dataset.amazon_review", "api/banhxeo.data.dataset.imdb", "api/banhxeo.data.loader", "api/banhxeo.data.torch", "api/banhxeo.data.transforms", "api/banhxeo.model", "api/banhxeo.model.base", "api/banhxeo.model.classic", "api/banhxeo.model.classic.gru", "api/banhxeo.model.classic.lstm", "api/banhxeo.model.classic.mlp", "api/banhxeo.model.classic.rnn", "api/banhxeo.model.classic.word2vec", "api/banhxeo.model.config", "api/banhxeo.model.llm", "api/banhxeo.model.llm.config", "api/banhxeo.model.llm.gpt2", "api/banhxeo.model.llm.layers", "api/banhxeo.model.llm.layers.layer_norm", "api/banhxeo.model.neural", "api/banhxeo.model.old", "api/banhxeo.model.old.n_gram", "api/banhxeo.train", "api/banhxeo.train.callbacks", "api/banhxeo.train.config", "api/banhxeo.train.trainer", "api/banhxeo.utils", "api/banhxeo.utils.file", "api/banhxeo.utils.logging", "api/modules", "index", "installation", "quickstart"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1}, "filenames": ["api/banhxeo.rst", "api/banhxeo.core.rst", "api/banhxeo.core.tokenizer.rst", "api/banhxeo.core.tokenizer.config.rst", "api/banhxeo.core.tokenizer.decoder.rst", "api/banhxeo.core.tokenizer.model.rst", "api/banhxeo.core.tokenizer.model.bpe.rst", "api/banhxeo.core.tokenizer.model.word.rst", "api/banhxeo.core.tokenizer.normalizers.rst", "api/banhxeo.core.tokenizer.post_processor.rst", "api/banhxeo.core.tokenizer.pre_tokenizer.rst", "api/banhxeo.core.tokenizer.presets.rst", "api/banhxeo.core.vocabulary.rst", "api/banhxeo.data.rst", "api/banhxeo.data.array.rst", "api/banhxeo.data.base.rst", "api/banhxeo.data.config.rst", "api/banhxeo.data.dataset.rst", "api/banhxeo.data.dataset.amazon_review.rst", "api/banhxeo.data.dataset.imdb.rst", "api/banhxeo.data.loader.rst", "api/banhxeo.data.torch.rst", "api/banhxeo.data.transforms.rst", "api/banhxeo.model.rst", "api/banhxeo.model.base.rst", "api/banhxeo.model.classic.rst", "api/banhxeo.model.classic.gru.rst", "api/banhxeo.model.classic.lstm.rst", "api/banhxeo.model.classic.mlp.rst", "api/banhxeo.model.classic.rnn.rst", "api/banhxeo.model.classic.word2vec.rst", "api/banhxeo.model.config.rst", "api/banhxeo.model.llm.rst", "api/banhxeo.model.llm.config.rst", "api/banhxeo.model.llm.gpt2.rst", "api/banhxeo.model.llm.layers.rst", "api/banhxeo.model.llm.layers.layer_norm.rst", "api/banhxeo.model.neural.rst", "api/banhxeo.model.old.rst", "api/banhxeo.model.old.n_gram.rst", "api/banhxeo.train.rst", "api/banhxeo.train.callbacks.rst", "api/banhxeo.train.config.rst", "api/banhxeo.train.trainer.rst", "api/banhxeo.utils.rst", "api/banhxeo.utils.file.rst", "api/banhxeo.utils.logging.rst", "api/modules.rst", "index.rst", "installation.rst", "quickstart.rst"], "indexentries": {"__init__() (banhxeo.core.gpttokenizer method)": [[1, "banhxeo.core.GPTTokenizer.__init__", false]], "__init__() (banhxeo.core.nltktokenizer method)": [[1, "banhxeo.core.NLTKTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.config.processconfig method)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.__init__", false]], "__init__() (banhxeo.core.tokenizer.config.specialtokens method)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.__init__", false]], "__init__() (banhxeo.core.tokenizer.config.token method)": [[3, "banhxeo.core.tokenizer.config.Token.__init__", false]], "__init__() (banhxeo.core.tokenizer.decoder.byteleveldecoder method)": [[4, "banhxeo.core.tokenizer.decoder.ByteLevelDecoder.__init__", false]], "__init__() (banhxeo.core.tokenizer.decoder.nltkdecoder method)": [[4, "banhxeo.core.tokenizer.decoder.NLTKDecoder.__init__", false]], "__init__() (banhxeo.core.tokenizer.model.bpe.bpemodel method)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel.__init__", false]], "__init__() (banhxeo.core.tokenizer.model.word.wordlevelmodel method)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel.__init__", false]], "__init__() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.__init__", false]], "__init__() (banhxeo.core.tokenizer.normalizers.sequencenormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.SequenceNormalizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.normalizers.stripnormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.StripNormalizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.post_processor.generalpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.bytelevelpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.ByteLevelPreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.nltkpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.NLTKPreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.pretokenizedstring method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizedString.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.punctuationpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PunctuationPreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.regexpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.RegexPreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.sequencepretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.SequencePreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.split method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.Split.__init__", false]], "__init__() (banhxeo.core.tokenizer.pre_tokenizer.whitespacepretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.WhiteSpacePreTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.presets.gpttokenizer method)": [[11, "banhxeo.core.tokenizer.presets.GPTTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.presets.nltktokenizer method)": [[11, "banhxeo.core.tokenizer.presets.NLTKTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.presets.simpletokenizer method)": [[11, "banhxeo.core.tokenizer.presets.SimpleTokenizer.__init__", false]], "__init__() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.__init__", false]], "__init__() (banhxeo.data.amazonreviewfulldataset method)": [[13, "banhxeo.data.AmazonReviewFullDataset.__init__", false]], "__init__() (banhxeo.data.array.arraydatasetconfig method)": [[14, "banhxeo.data.array.ArrayDatasetConfig.__init__", false]], "__init__() (banhxeo.data.array.arraytextdataset method)": [[14, "banhxeo.data.array.ArrayTextDataset.__init__", false]], "__init__() (banhxeo.data.base.basetextdataset method)": [[15, "banhxeo.data.base.BaseTextDataset.__init__", false]], "__init__() (banhxeo.data.base.datasetconfig method)": [[15, "banhxeo.data.base.DatasetConfig.__init__", false]], "__init__() (banhxeo.data.base.datasetsplit method)": [[15, "banhxeo.data.base.DatasetSplit.__init__", false]], "__init__() (banhxeo.data.base.downloaddatasetfile method)": [[15, "banhxeo.data.base.DownloadDatasetFile.__init__", false]], "__init__() (banhxeo.data.dataset.amazon_review.amazonreviewfulldataset method)": [[18, "banhxeo.data.dataset.amazon_review.AmazonReviewFullDataset.__init__", false]], "__init__() (banhxeo.data.dataset.imdb.imdbdataset method)": [[19, "banhxeo.data.dataset.imdb.IMDBDataset.__init__", false]], "__init__() (banhxeo.data.imdbdataset method)": [[13, "banhxeo.data.IMDBDataset.__init__", false]], "__init__() (banhxeo.data.loader.dataloader method)": [[20, "banhxeo.data.loader.DataLoader.__init__", false]], "__init__() (banhxeo.data.loader.naivedataloader method)": [[20, "banhxeo.data.loader.NaiveDataLoader.__init__", false]], "__init__() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.__init__", false]], "add() (banhxeo.core.tokenizer.normalizers.sequencenormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.SequenceNormalizer.add", false]], "add() (banhxeo.core.tokenizer.pre_tokenizer.sequencepretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.SequencePreTokenizer.add", false]], "add_special_tokens (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.add_special_tokens", false]], "alignments (banhxeo.core.tokenizer.normalizers.normalizedstring attribute)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.alignments", false]], "amazonreviewfulldataset (class in banhxeo.data)": [[13, "banhxeo.data.AmazonReviewFullDataset", false]], "amazonreviewfulldataset (class in banhxeo.data.dataset.amazon_review)": [[18, "banhxeo.data.dataset.amazon_review.AmazonReviewFullDataset", false]], "append() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.append", false]], "arraydatasetconfig (class in banhxeo.data.array)": [[14, "banhxeo.data.array.ArrayDatasetConfig", false]], "arraytextdataset (class in banhxeo.data.array)": [[14, "banhxeo.data.array.ArrayTextDataset", false]], "banhxeo": [[0, "module-banhxeo", false]], "banhxeo.core": [[1, "module-banhxeo.core", false]], "banhxeo.core.tokenizer": [[2, "module-banhxeo.core.tokenizer", false]], "banhxeo.core.tokenizer.config": [[3, "module-banhxeo.core.tokenizer.config", false]], "banhxeo.core.tokenizer.decoder": [[4, "module-banhxeo.core.tokenizer.decoder", false]], "banhxeo.core.tokenizer.model": [[5, "module-banhxeo.core.tokenizer.model", false]], "banhxeo.core.tokenizer.model.bpe": [[6, "module-banhxeo.core.tokenizer.model.bpe", false]], "banhxeo.core.tokenizer.model.word": [[7, "module-banhxeo.core.tokenizer.model.word", false]], "banhxeo.core.tokenizer.normalizers": [[8, "module-banhxeo.core.tokenizer.normalizers", false]], "banhxeo.core.tokenizer.post_processor": [[9, "module-banhxeo.core.tokenizer.post_processor", false]], "banhxeo.core.tokenizer.pre_tokenizer": [[10, "module-banhxeo.core.tokenizer.pre_tokenizer", false]], "banhxeo.core.tokenizer.presets": [[11, "module-banhxeo.core.tokenizer.presets", false]], "banhxeo.data": [[13, "module-banhxeo.data", false]], "banhxeo.data.array": [[14, "module-banhxeo.data.array", false]], "banhxeo.data.base": [[15, "module-banhxeo.data.base", false]], "banhxeo.data.dataset": [[17, "module-banhxeo.data.dataset", false]], "banhxeo.data.dataset.amazon_review": [[18, "module-banhxeo.data.dataset.amazon_review", false]], "banhxeo.data.dataset.imdb": [[19, "module-banhxeo.data.dataset.imdb", false]], "banhxeo.data.loader": [[20, "module-banhxeo.data.loader", false]], "banhxeo.utils": [[44, "module-banhxeo.utils", false]], "banhxeo.utils.file": [[45, "module-banhxeo.utils.file", false]], "banhxeo.utils.logging": [[46, "module-banhxeo.utils.logging", false]], "basetextdataset (class in banhxeo.data.base)": [[15, "banhxeo.data.base.BaseTextDataset", false]], "batch_decode() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.batch_decode", false]], "batch_encode() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.batch_encode", false]], "bertpostprocessor (class in banhxeo.core.tokenizer.post_processor)": [[9, "banhxeo.core.tokenizer.post_processor.BertPostProcessor", false]], "bos_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.bos_tok", false]], "bpemodel (class in banhxeo.core.tokenizer.model.bpe)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel", false]], "byteleveldecoder (class in banhxeo.core.tokenizer.decoder)": [[4, "banhxeo.core.tokenizer.decoder.ByteLevelDecoder", false]], "bytelevelpretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.ByteLevelPreTokenizer", false]], "bytes_to_unicode() (in module banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.bytes_to_unicode", false]], "check_and_raise() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.check_and_raise", false]], "check_md5() (in module banhxeo.utils.file)": [[45, "banhxeo.utils.file.check_md5", false]], "cls_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.cls_tok", false]], "colab (banhxeo.utils.runtimeenv attribute)": [[44, "banhxeo.utils.RuntimeEnv.COLAB", false]], "dataloader (class in banhxeo.data.loader)": [[20, "banhxeo.data.loader.DataLoader", false]], "datasetconfig (class in banhxeo.data.base)": [[15, "banhxeo.data.base.DatasetConfig", false]], "datasetsplit (class in banhxeo.data.base)": [[15, "banhxeo.data.base.DatasetSplit", false]], "debug() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.debug", false]], "debug() (banhxeo.utils.logging.printlogger method)": [[46, "banhxeo.utils.logging.PrintLogger.debug", false]], "decode() (banhxeo.core.tokenizer.decoder.byteleveldecoder method)": [[4, "banhxeo.core.tokenizer.decoder.ByteLevelDecoder.decode", false]], "decode() (banhxeo.core.tokenizer.decoder.decoder method)": [[4, "banhxeo.core.tokenizer.decoder.Decoder.decode", false]], "decode() (banhxeo.core.tokenizer.decoder.nltkdecoder method)": [[4, "banhxeo.core.tokenizer.decoder.NLTKDecoder.decode", false]], "decode() (banhxeo.core.tokenizer.decoder.whitespacedecoder method)": [[4, "banhxeo.core.tokenizer.decoder.WhiteSpaceDecoder.decode", false]], "decode() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.decode", false]], "decoder (class in banhxeo.core.tokenizer.decoder)": [[4, "banhxeo.core.tokenizer.decoder.Decoder", false]], "detokenize() (banhxeo.core.tokenizer.model.bpe.bpemodel method)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel.detokenize", false]], "detokenize() (banhxeo.core.tokenizer.model.tokenizermodel method)": [[5, "banhxeo.core.tokenizer.model.TokenizerModel.detokenize", false]], "detokenize() (banhxeo.core.tokenizer.model.word.wordlevelmodel method)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel.detokenize", false]], "dict() (banhxeo.core.tokenizer.config.processconfig method)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.dict", false]], "download_archive() (in module banhxeo.utils.file)": [[45, "banhxeo.utils.file.download_archive", false]], "downloaddatasetfile (class in banhxeo.data.base)": [[15, "banhxeo.data.base.DownloadDatasetFile", false]], "encode() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.encode", false]], "encode_config (banhxeo.data.array.arraydatasetconfig attribute)": [[14, "banhxeo.data.array.ArrayDatasetConfig.encode_config", false]], "eos_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.eos_tok", false]], "error() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.error", false]], "error() (banhxeo.utils.logging.printlogger method)": [[46, "banhxeo.utils.logging.PrintLogger.error", false]], "exception() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.exception", false]], "exception() (banhxeo.utils.logging.printlogger method)": [[46, "banhxeo.utils.logging.PrintLogger.exception", false]], "ext (banhxeo.data.base.downloaddatasetfile attribute)": [[15, "banhxeo.data.base.DownloadDatasetFile.ext", false]], "extract_archive() (in module banhxeo.utils.file)": [[45, "banhxeo.utils.file.extract_archive", false]], "file_info (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.file_info", false]], "filter() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.filter", false]], "from_config() (banhxeo.core.tokenizer.model.bpe.bpemodel class method)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel.from_config", false]], "from_config() (banhxeo.core.tokenizer.model.tokenizermodel class method)": [[5, "banhxeo.core.tokenizer.model.TokenizerModel.from_config", false]], "from_config() (banhxeo.core.tokenizer.model.word.wordlevelmodel class method)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel.from_config", false]], "from_pretrained() (banhxeo.core.tokenizer.tokenizer class method)": [[2, "banhxeo.core.tokenizer.Tokenizer.from_pretrained", false]], "from_str() (banhxeo.core.tokenizer.normalizers.normalizedstring class method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.from_str", false]], "generalpostprocessor (class in banhxeo.core.tokenizer.post_processor)": [[9, "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor", false]], "get() (banhxeo.data.array.arraytextdataset method)": [[14, "banhxeo.data.array.ArrayTextDataset.get", false]], "get_all_texts() (banhxeo.data.base.basetextdataset method)": [[15, "banhxeo.data.base.BaseTextDataset.get_all_texts", false]], "get_data() (banhxeo.data.base.basetextdataset method)": [[15, "banhxeo.data.base.BaseTextDataset.get_data", false]], "get_pair_stats() (in module banhxeo.core.tokenizer.model.bpe)": [[6, "banhxeo.core.tokenizer.model.bpe.get_pair_stats", false]], "get_runtime() (in module banhxeo.utils)": [[44, "banhxeo.utils.get_runtime", false]], "gptpostprocessor (class in banhxeo.core.tokenizer.post_processor)": [[9, "banhxeo.core.tokenizer.post_processor.GPTPostProcessor", false]], "gpttokenizer (class in banhxeo.core)": [[1, "banhxeo.core.GPTTokenizer", false]], "gpttokenizer (class in banhxeo.core.tokenizer.presets)": [[11, "banhxeo.core.tokenizer.presets.GPTTokenizer", false]], "hf_name (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.hf_name", false]], "hf_path (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.hf_path", false]], "hfdataset (class in banhxeo.data)": [[13, "banhxeo.data.HFDataset", false]], "hfdataset (class in banhxeo.data.base)": [[15, "banhxeo.data.base.HFDataset", false]], "id (banhxeo.core.tokenizer.config.token attribute)": [[3, "banhxeo.core.tokenizer.config.Token.id", false]], "imdbdataset (class in banhxeo.data)": [[13, "banhxeo.data.IMDBDataset", false]], "imdbdataset (class in banhxeo.data.dataset.imdb)": [[19, "banhxeo.data.dataset.imdb.IMDBDataset", false]], "info() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.info", false]], "info() (banhxeo.utils.logging.printlogger method)": [[46, "banhxeo.utils.logging.PrintLogger.info", false]], "ipython (banhxeo.utils.runtimeenv attribute)": [[44, "banhxeo.utils.RuntimeEnv.IPYTHON", false]], "is_classification (banhxeo.data.array.arraydatasetconfig attribute)": [[14, "banhxeo.data.array.ArrayDatasetConfig.is_classification", false]], "jupyter (banhxeo.utils.runtimeenv attribute)": [[44, "banhxeo.utils.RuntimeEnv.JUPYTER", false]], "label_column (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.label_column", false]], "label_map (banhxeo.data.array.arraydatasetconfig attribute)": [[14, "banhxeo.data.array.ArrayDatasetConfig.label_map", false]], "load() (banhxeo.data.base.hfdataset class method)": [[15, "banhxeo.data.base.HFDataset.load", false]], "load() (banhxeo.data.hfdataset class method)": [[13, "banhxeo.data.HFDataset.load", false]], "load_json() (in module banhxeo.utils.file)": [[45, "banhxeo.utils.file.load_json", false]], "logger (class in banhxeo.utils.logging)": [[46, "banhxeo.utils.logging.Logger", false]], "lowercasenormalizer (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.LowercaseNormalizer", false]], "mask_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.mask_tok", false]], "max_length (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.max_length", false]], "md5 (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.md5", false]], "merge_pair() (in module banhxeo.core.tokenizer.model.bpe)": [[6, "banhxeo.core.tokenizer.model.bpe.merge_pair", false]], "module": [[0, "module-banhxeo", false], [1, "module-banhxeo.core", false], [2, "module-banhxeo.core.tokenizer", false], [3, "module-banhxeo.core.tokenizer.config", false], [4, "module-banhxeo.core.tokenizer.decoder", false], [5, "module-banhxeo.core.tokenizer.model", false], [6, "module-banhxeo.core.tokenizer.model.bpe", false], [7, "module-banhxeo.core.tokenizer.model.word", false], [8, "module-banhxeo.core.tokenizer.normalizers", false], [9, "module-banhxeo.core.tokenizer.post_processor", false], [10, "module-banhxeo.core.tokenizer.pre_tokenizer", false], [11, "module-banhxeo.core.tokenizer.presets", false], [13, "module-banhxeo.data", false], [14, "module-banhxeo.data.array", false], [15, "module-banhxeo.data.base", false], [17, "module-banhxeo.data.dataset", false], [18, "module-banhxeo.data.dataset.amazon_review", false], [19, "module-banhxeo.data.dataset.imdb", false], [20, "module-banhxeo.data.loader", false], [44, "module-banhxeo.utils", false], [45, "module-banhxeo.utils.file", false], [46, "module-banhxeo.utils.logging", false]], "naivedataloader (class in banhxeo.data.loader)": [[20, "banhxeo.data.loader.NaiveDataLoader", false]], "name (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.name", false]], "name (banhxeo.data.base.downloaddatasetfile attribute)": [[15, "banhxeo.data.base.DownloadDatasetFile.name", false]], "nfcnormalizer (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.NFCNormalizer", false]], "nltkdecoder (class in banhxeo.core.tokenizer.decoder)": [[4, "banhxeo.core.tokenizer.decoder.NLTKDecoder", false]], "nltkpretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.NLTKPreTokenizer", false]], "nltktokenizer (class in banhxeo.core)": [[1, "banhxeo.core.NLTKTokenizer", false]], "nltktokenizer (class in banhxeo.core.tokenizer.presets)": [[11, "banhxeo.core.tokenizer.presets.NLTKTokenizer", false]], "normalize() (banhxeo.core.tokenizer.normalizers.lowercasenormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.LowercaseNormalizer.normalize", false]], "normalize() (banhxeo.core.tokenizer.normalizers.nfcnormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.NFCNormalizer.normalize", false]], "normalize() (banhxeo.core.tokenizer.normalizers.normalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.Normalizer.normalize", false]], "normalize() (banhxeo.core.tokenizer.normalizers.sequencenormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.SequenceNormalizer.normalize", false]], "normalize() (banhxeo.core.tokenizer.normalizers.stripnormalizer method)": [[8, "banhxeo.core.tokenizer.normalizers.StripNormalizer.normalize", false]], "normalized (banhxeo.core.tokenizer.normalizers.normalizedstring attribute)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.normalized", false]], "normalized (banhxeo.core.tokenizer.pre_tokenizer.split attribute)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.Split.normalized", false]], "normalizedstring (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString", false]], "normalizer (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.Normalizer", false]], "offsets (banhxeo.core.tokenizer.config.token attribute)": [[3, "banhxeo.core.tokenizer.config.Token.offsets", false]], "original (banhxeo.core.tokenizer.normalizers.normalizedstring attribute)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.original", false]], "original_shift (banhxeo.core.tokenizer.normalizers.normalizedstring attribute)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.original_shift", false]], "pad_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.pad_tok", false]], "padding (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.padding", false]], "padding_side (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.padding_side", false]], "postprocessor (class in banhxeo.core.tokenizer.post_processor)": [[9, "banhxeo.core.tokenizer.post_processor.PostProcessor", false]], "pre_tokenize() (banhxeo.core.tokenizer.pre_tokenizer.bytelevelpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.ByteLevelPreTokenizer.pre_tokenize", false]], "pre_tokenize() (banhxeo.core.tokenizer.pre_tokenizer.nltkpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.NLTKPreTokenizer.pre_tokenize", false]], "pre_tokenize() (banhxeo.core.tokenizer.pre_tokenizer.pretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizer.pre_tokenize", false]], "pre_tokenize() (banhxeo.core.tokenizer.pre_tokenizer.regexpretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.RegexPreTokenizer.pre_tokenize", false]], "pre_tokenize() (banhxeo.core.tokenizer.pre_tokenizer.sequencepretokenizer method)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.SequencePreTokenizer.pre_tokenize", false]], "prepend() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.prepend", false]], "pretokenizedstring (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizedString", false]], "pretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizer", false]], "printlogger (class in banhxeo.utils.logging)": [[46, "banhxeo.utils.logging.PrintLogger", false]], "process() (banhxeo.core.tokenizer.post_processor.generalpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor.process", false]], "process() (banhxeo.core.tokenizer.post_processor.postprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.PostProcessor.process", false]], "process_batch() (banhxeo.core.tokenizer.post_processor.generalpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor.process_batch", false]], "process_batch() (banhxeo.core.tokenizer.post_processor.postprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.PostProcessor.process_batch", false]], "process_tokens() (banhxeo.core.tokenizer.post_processor.bertpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.BertPostProcessor.process_tokens", false]], "process_tokens() (banhxeo.core.tokenizer.post_processor.generalpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor.process_tokens", false]], "process_tokens() (banhxeo.core.tokenizer.post_processor.gptpostprocessor method)": [[9, "banhxeo.core.tokenizer.post_processor.GPTPostProcessor.process_tokens", false]], "processconfig (class in banhxeo.core.tokenizer.config)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig", false]], "punctuationpretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PunctuationPreTokenizer", false]], "regexpretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.RegexPreTokenizer", false]], "resv_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.resv_tok", false]], "return_tensors (banhxeo.data.array.arraydatasetconfig attribute)": [[14, "banhxeo.data.array.ArrayDatasetConfig.return_tensors", false]], "runtimeenv (class in banhxeo.utils)": [[44, "banhxeo.utils.RuntimeEnv", false]], "sep_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.sep_tok", false]], "sequencenormalizer (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.SequenceNormalizer", false]], "sequencepretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.SequencePreTokenizer", false]], "shell (banhxeo.utils.runtimeenv attribute)": [[44, "banhxeo.utils.RuntimeEnv.SHELL", false]], "simpletokenizer (class in banhxeo.core.tokenizer.presets)": [[11, "banhxeo.core.tokenizer.presets.SimpleTokenizer", false]], "slice() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.slice", false]], "source (banhxeo.data.base.downloaddatasetfile attribute)": [[15, "banhxeo.data.base.DownloadDatasetFile.source", false]], "special_token_idx() (banhxeo.core.tokenizer.config.specialtokens method)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.special_token_idx", false]], "special_tokens (banhxeo.core.tokenizer.config.specialtokens property)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.special_tokens", false]], "specialtokens (class in banhxeo.core.tokenizer.config)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens", false]], "split (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.split", false]], "split (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.Split", false]], "splits (banhxeo.core.tokenizer.pre_tokenizer.pretokenizedstring attribute)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizedString.splits", false]], "stripnormalizer (class in banhxeo.core.tokenizer.normalizers)": [[8, "banhxeo.core.tokenizer.normalizers.StripNormalizer", false]], "template (banhxeo.utils.logging.printlogger attribute)": [[46, "banhxeo.utils.logging.PrintLogger.template", false]], "test (banhxeo.data.base.datasetsplit attribute)": [[15, "banhxeo.data.base.DatasetSplit.test", false]], "text_column (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.text_column", false]], "to_array() (banhxeo.data.base.basetextdataset method)": [[15, "banhxeo.data.base.BaseTextDataset.to_array", false]], "to_loader() (banhxeo.data.array.arraytextdataset method)": [[14, "banhxeo.data.array.ArrayTextDataset.to_loader", false]], "token (class in banhxeo.core.tokenizer.config)": [[3, "banhxeo.core.tokenizer.config.Token", false]], "tokenize() (banhxeo.core.tokenizer.model.bpe.bpemodel method)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel.tokenize", false]], "tokenize() (banhxeo.core.tokenizer.model.tokenizermodel method)": [[5, "banhxeo.core.tokenizer.model.TokenizerModel.tokenize", false]], "tokenize() (banhxeo.core.tokenizer.model.word.wordlevelmodel method)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel.tokenize", false]], "tokenizer (banhxeo.data.array.arraydatasetconfig attribute)": [[14, "banhxeo.data.array.ArrayDatasetConfig.tokenizer", false]], "tokenizer (class in banhxeo.core.tokenizer)": [[2, "banhxeo.core.tokenizer.Tokenizer", false]], "tokenizermodel (class in banhxeo.core.tokenizer.model)": [[5, "banhxeo.core.tokenizer.model.TokenizerModel", false]], "tokens (banhxeo.core.tokenizer.pre_tokenizer.split attribute)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.Split.tokens", false]], "train (banhxeo.data.base.datasetsplit attribute)": [[15, "banhxeo.data.base.DatasetSplit.train", false]], "train() (banhxeo.core.tokenizer.model.bpe.bpemodel method)": [[6, "banhxeo.core.tokenizer.model.bpe.BPEModel.train", false]], "train() (banhxeo.core.tokenizer.model.tokenizermodel method)": [[5, "banhxeo.core.tokenizer.model.TokenizerModel.train", false]], "train() (banhxeo.core.tokenizer.model.word.wordlevelmodel method)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel.train", false]], "train() (banhxeo.core.tokenizer.tokenizer method)": [[2, "banhxeo.core.tokenizer.Tokenizer.train", false]], "transform() (banhxeo.core.tokenizer.normalizers.normalizedstring method)": [[8, "banhxeo.core.tokenizer.normalizers.NormalizedString.transform", false]], "truncation (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.truncation", false]], "truncation_side (banhxeo.core.tokenizer.config.processconfig attribute)": [[3, "banhxeo.core.tokenizer.config.ProcessConfig.truncation_side", false]], "unk_tok (banhxeo.core.tokenizer.config.specialtokens attribute)": [[3, "banhxeo.core.tokenizer.config.SpecialTokens.unk_tok", false]], "url (banhxeo.data.base.datasetconfig attribute)": [[15, "banhxeo.data.base.DatasetConfig.url", false]], "val (banhxeo.data.base.datasetsplit attribute)": [[15, "banhxeo.data.base.DatasetSplit.val", false]], "validate_config() (in module banhxeo.utils)": [[44, "banhxeo.utils.validate_config", false]], "value (banhxeo.core.tokenizer.config.token attribute)": [[3, "banhxeo.core.tokenizer.config.Token.value", false]], "warning() (banhxeo.utils.logging.logger method)": [[46, "banhxeo.utils.logging.Logger.warning", false]], "warning() (banhxeo.utils.logging.printlogger method)": [[46, "banhxeo.utils.logging.PrintLogger.warning", false]], "whitespacedecoder (class in banhxeo.core.tokenizer.decoder)": [[4, "banhxeo.core.tokenizer.decoder.WhiteSpaceDecoder", false]], "whitespacepretokenizer (class in banhxeo.core.tokenizer.pre_tokenizer)": [[10, "banhxeo.core.tokenizer.pre_tokenizer.WhiteSpacePreTokenizer", false]], "wordlevelmodel (class in banhxeo.core.tokenizer.model.word)": [[7, "banhxeo.core.tokenizer.model.word.WordLevelModel", false]]}, "objects": {"": [[0, 0, 0, "-", "banhxeo"]], "banhxeo": [[1, 0, 0, "-", "core"], [13, 0, 0, "-", "data"], [44, 0, 0, "-", "utils"]], "banhxeo.core": [[1, 1, 1, "", "GPTTokenizer"], [1, 1, 1, "", "NLTKTokenizer"], [2, 0, 0, "-", "tokenizer"]], "banhxeo.core.GPTTokenizer": [[1, 2, 1, "", "__init__"]], "banhxeo.core.NLTKTokenizer": [[1, 2, 1, "", "__init__"]], "banhxeo.core.tokenizer": [[2, 1, 1, "", "Tokenizer"], [3, 0, 0, "-", "config"], [4, 0, 0, "-", "decoder"], [5, 0, 0, "-", "model"], [8, 0, 0, "-", "normalizers"], [9, 0, 0, "-", "post_processor"], [10, 0, 0, "-", "pre_tokenizer"], [11, 0, 0, "-", "presets"]], "banhxeo.core.tokenizer.Tokenizer": [[2, 2, 1, "", "__init__"], [2, 2, 1, "", "batch_decode"], [2, 2, 1, "", "batch_encode"], [2, 2, 1, "", "decode"], [2, 2, 1, "", "encode"], [2, 2, 1, "", "from_pretrained"], [2, 2, 1, "", "train"]], "banhxeo.core.tokenizer.config": [[3, 1, 1, "", "ProcessConfig"], [3, 1, 1, "", "SpecialTokens"], [3, 1, 1, "", "Token"]], "banhxeo.core.tokenizer.config.ProcessConfig": [[3, 2, 1, "", "__init__"], [3, 3, 1, "", "add_special_tokens"], [3, 2, 1, "", "dict"], [3, 3, 1, "", "max_length"], [3, 3, 1, "", "padding"], [3, 3, 1, "", "padding_side"], [3, 3, 1, "", "truncation"], [3, 3, 1, "", "truncation_side"]], "banhxeo.core.tokenizer.config.SpecialTokens": [[3, 2, 1, "", "__init__"], [3, 3, 1, "", "bos_tok"], [3, 3, 1, "", "cls_tok"], [3, 3, 1, "", "eos_tok"], [3, 3, 1, "", "mask_tok"], [3, 3, 1, "", "pad_tok"], [3, 3, 1, "", "resv_tok"], [3, 3, 1, "", "sep_tok"], [3, 2, 1, "", "special_token_idx"], [3, 4, 1, "", "special_tokens"], [3, 3, 1, "", "unk_tok"]], "banhxeo.core.tokenizer.config.Token": [[3, 2, 1, "", "__init__"], [3, 3, 1, "", "id"], [3, 3, 1, "", "offsets"], [3, 3, 1, "", "value"]], "banhxeo.core.tokenizer.decoder": [[4, 1, 1, "", "ByteLevelDecoder"], [4, 1, 1, "", "Decoder"], [4, 1, 1, "", "NLTKDecoder"], [4, 1, 1, "", "WhiteSpaceDecoder"]], "banhxeo.core.tokenizer.decoder.ByteLevelDecoder": [[4, 2, 1, "", "__init__"], [4, 2, 1, "", "decode"]], "banhxeo.core.tokenizer.decoder.Decoder": [[4, 2, 1, "", "decode"]], "banhxeo.core.tokenizer.decoder.NLTKDecoder": [[4, 2, 1, "", "__init__"], [4, 2, 1, "", "decode"]], "banhxeo.core.tokenizer.decoder.WhiteSpaceDecoder": [[4, 2, 1, "", "decode"]], "banhxeo.core.tokenizer.model": [[5, 1, 1, "", "TokenizerModel"], [6, 0, 0, "-", "bpe"], [7, 0, 0, "-", "word"]], "banhxeo.core.tokenizer.model.TokenizerModel": [[5, 2, 1, "", "detokenize"], [5, 2, 1, "", "from_config"], [5, 2, 1, "", "tokenize"], [5, 2, 1, "", "train"]], "banhxeo.core.tokenizer.model.bpe": [[6, 1, 1, "", "BPEModel"], [6, 5, 1, "", "get_pair_stats"], [6, 5, 1, "", "merge_pair"]], "banhxeo.core.tokenizer.model.bpe.BPEModel": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "detokenize"], [6, 2, 1, "", "from_config"], [6, 2, 1, "", "tokenize"], [6, 2, 1, "", "train"]], "banhxeo.core.tokenizer.model.word": [[7, 1, 1, "", "WordLevelModel"]], "banhxeo.core.tokenizer.model.word.WordLevelModel": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "detokenize"], [7, 2, 1, "", "from_config"], [7, 2, 1, "", "tokenize"], [7, 2, 1, "", "train"]], "banhxeo.core.tokenizer.normalizers": [[8, 1, 1, "", "LowercaseNormalizer"], [8, 1, 1, "", "NFCNormalizer"], [8, 1, 1, "", "NormalizedString"], [8, 1, 1, "", "Normalizer"], [8, 1, 1, "", "SequenceNormalizer"], [8, 1, 1, "", "StripNormalizer"]], "banhxeo.core.tokenizer.normalizers.LowercaseNormalizer": [[8, 2, 1, "", "normalize"]], "banhxeo.core.tokenizer.normalizers.NFCNormalizer": [[8, 2, 1, "", "normalize"]], "banhxeo.core.tokenizer.normalizers.NormalizedString": [[8, 2, 1, "", "__init__"], [8, 3, 1, "", "alignments"], [8, 2, 1, "", "append"], [8, 2, 1, "", "filter"], [8, 2, 1, "", "from_str"], [8, 3, 1, "", "normalized"], [8, 3, 1, "", "original"], [8, 3, 1, "", "original_shift"], [8, 2, 1, "", "prepend"], [8, 2, 1, "", "slice"], [8, 2, 1, "", "transform"]], "banhxeo.core.tokenizer.normalizers.Normalizer": [[8, 2, 1, "", "normalize"]], "banhxeo.core.tokenizer.normalizers.SequenceNormalizer": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "add"], [8, 2, 1, "", "normalize"]], "banhxeo.core.tokenizer.normalizers.StripNormalizer": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "normalize"]], "banhxeo.core.tokenizer.post_processor": [[9, 1, 1, "", "BertPostProcessor"], [9, 1, 1, "", "GPTPostProcessor"], [9, 1, 1, "", "GeneralPostProcessor"], [9, 1, 1, "", "PostProcessor"]], "banhxeo.core.tokenizer.post_processor.BertPostProcessor": [[9, 2, 1, "", "process_tokens"]], "banhxeo.core.tokenizer.post_processor.GPTPostProcessor": [[9, 2, 1, "", "process_tokens"]], "banhxeo.core.tokenizer.post_processor.GeneralPostProcessor": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "process"], [9, 2, 1, "", "process_batch"], [9, 2, 1, "", "process_tokens"]], "banhxeo.core.tokenizer.post_processor.PostProcessor": [[9, 2, 1, "", "process"], [9, 2, 1, "", "process_batch"]], "banhxeo.core.tokenizer.pre_tokenizer": [[10, 1, 1, "", "ByteLevelPreTokenizer"], [10, 1, 1, "", "NLTKPreTokenizer"], [10, 1, 1, "", "PreTokenizedString"], [10, 1, 1, "", "PreTokenizer"], [10, 1, 1, "", "PunctuationPreTokenizer"], [10, 1, 1, "", "RegexPreTokenizer"], [10, 1, 1, "", "SequencePreTokenizer"], [10, 1, 1, "", "Split"], [10, 1, 1, "", "WhiteSpacePreTokenizer"], [10, 5, 1, "", "bytes_to_unicode"]], "banhxeo.core.tokenizer.pre_tokenizer.ByteLevelPreTokenizer": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "pre_tokenize"]], "banhxeo.core.tokenizer.pre_tokenizer.NLTKPreTokenizer": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "pre_tokenize"]], "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizedString": [[10, 2, 1, "", "__init__"], [10, 3, 1, "", "splits"]], "banhxeo.core.tokenizer.pre_tokenizer.PreTokenizer": [[10, 2, 1, "", "pre_tokenize"]], "banhxeo.core.tokenizer.pre_tokenizer.PunctuationPreTokenizer": [[10, 2, 1, "", "__init__"]], "banhxeo.core.tokenizer.pre_tokenizer.RegexPreTokenizer": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "pre_tokenize"]], "banhxeo.core.tokenizer.pre_tokenizer.SequencePreTokenizer": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "add"], [10, 2, 1, "", "pre_tokenize"]], "banhxeo.core.tokenizer.pre_tokenizer.Split": [[10, 2, 1, "", "__init__"], [10, 3, 1, "", "normalized"], [10, 3, 1, "", "tokens"]], "banhxeo.core.tokenizer.pre_tokenizer.WhiteSpacePreTokenizer": [[10, 2, 1, "", "__init__"]], "banhxeo.core.tokenizer.presets": [[11, 1, 1, "", "GPTTokenizer"], [11, 1, 1, "", "NLTKTokenizer"], [11, 1, 1, "", "SimpleTokenizer"]], "banhxeo.core.tokenizer.presets.GPTTokenizer": [[11, 2, 1, "", "__init__"]], "banhxeo.core.tokenizer.presets.NLTKTokenizer": [[11, 2, 1, "", "__init__"]], "banhxeo.core.tokenizer.presets.SimpleTokenizer": [[11, 2, 1, "", "__init__"]], "banhxeo.data": [[13, 1, 1, "", "AmazonReviewFullDataset"], [13, 1, 1, "", "HFDataset"], [13, 1, 1, "", "IMDBDataset"], [14, 0, 0, "-", "array"], [15, 0, 0, "-", "base"], [17, 0, 0, "-", "dataset"], [20, 0, 0, "-", "loader"]], "banhxeo.data.AmazonReviewFullDataset": [[13, 2, 1, "", "__init__"]], "banhxeo.data.HFDataset": [[13, 2, 1, "", "load"]], "banhxeo.data.IMDBDataset": [[13, 2, 1, "", "__init__"]], "banhxeo.data.array": [[14, 1, 1, "", "ArrayDatasetConfig"], [14, 1, 1, "", "ArrayTextDataset"]], "banhxeo.data.array.ArrayDatasetConfig": [[14, 2, 1, "", "__init__"], [14, 3, 1, "", "encode_config"], [14, 3, 1, "", "is_classification"], [14, 3, 1, "", "label_map"], [14, 3, 1, "", "return_tensors"], [14, 3, 1, "", "tokenizer"]], "banhxeo.data.array.ArrayTextDataset": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "get"], [14, 2, 1, "", "to_loader"]], "banhxeo.data.base": [[15, 1, 1, "", "BaseTextDataset"], [15, 1, 1, "", "DatasetConfig"], [15, 1, 1, "", "DatasetSplit"], [15, 1, 1, "", "DownloadDatasetFile"], [15, 1, 1, "", "HFDataset"]], "banhxeo.data.base.BaseTextDataset": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "get_all_texts"], [15, 2, 1, "", "get_data"], [15, 2, 1, "", "to_array"]], "banhxeo.data.base.DatasetConfig": [[15, 2, 1, "", "__init__"], [15, 3, 1, "", "file_info"], [15, 3, 1, "", "hf_name"], [15, 3, 1, "", "hf_path"], [15, 3, 1, "", "label_column"], [15, 3, 1, "", "md5"], [15, 3, 1, "", "name"], [15, 3, 1, "", "split"], [15, 3, 1, "", "text_column"], [15, 3, 1, "", "url"]], "banhxeo.data.base.DatasetSplit": [[15, 2, 1, "", "__init__"], [15, 3, 1, "", "test"], [15, 3, 1, "", "train"], [15, 3, 1, "", "val"]], "banhxeo.data.base.DownloadDatasetFile": [[15, 2, 1, "", "__init__"], [15, 3, 1, "", "ext"], [15, 3, 1, "", "name"], [15, 3, 1, "", "source"]], "banhxeo.data.base.HFDataset": [[15, 2, 1, "", "load"]], "banhxeo.data.dataset": [[18, 0, 0, "-", "amazon_review"], [19, 0, 0, "-", "imdb"]], "banhxeo.data.dataset.amazon_review": [[18, 1, 1, "", "AmazonReviewFullDataset"]], "banhxeo.data.dataset.amazon_review.AmazonReviewFullDataset": [[18, 2, 1, "", "__init__"]], "banhxeo.data.dataset.imdb": [[19, 1, 1, "", "IMDBDataset"]], "banhxeo.data.dataset.imdb.IMDBDataset": [[19, 2, 1, "", "__init__"]], "banhxeo.data.loader": [[20, 1, 1, "", "DataLoader"], [20, 1, 1, "", "NaiveDataLoader"]], "banhxeo.data.loader.DataLoader": [[20, 2, 1, "", "__init__"]], "banhxeo.data.loader.NaiveDataLoader": [[20, 2, 1, "", "__init__"]], "banhxeo.utils": [[44, 1, 1, "", "RuntimeEnv"], [45, 0, 0, "-", "file"], [44, 5, 1, "", "get_runtime"], [46, 0, 0, "-", "logging"], [44, 5, 1, "", "validate_config"]], "banhxeo.utils.RuntimeEnv": [[44, 3, 1, "", "COLAB"], [44, 3, 1, "", "IPYTHON"], [44, 3, 1, "", "JUPYTER"], [44, 3, 1, "", "SHELL"]], "banhxeo.utils.file": [[45, 5, 1, "", "check_md5"], [45, 5, 1, "", "download_archive"], [45, 5, 1, "", "extract_archive"], [45, 5, 1, "", "load_json"]], "banhxeo.utils.logging": [[46, 1, 1, "", "Logger"], [46, 1, 1, "", "PrintLogger"]], "banhxeo.utils.logging.Logger": [[46, 2, 1, "", "__init__"], [46, 2, 1, "", "check_and_raise"], [46, 2, 1, "", "debug"], [46, 2, 1, "", "error"], [46, 2, 1, "", "exception"], [46, 2, 1, "", "info"], [46, 2, 1, "", "warning"]], "banhxeo.utils.logging.PrintLogger": [[46, 2, 1, "", "debug"], [46, 2, 1, "", "error"], [46, 2, 1, "", "exception"], [46, 2, 1, "", "info"], [46, 3, 1, "", "template"], [46, 2, 1, "", "warning"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "terms": {"": 8, "0": [3, 15, 20], "1": [3, 8, 15, 44], "1234": [13, 14, 15, 18, 19], "2": [3, 10, 44], "21": 8, "3": [3, 8, 44, 49], "32": 14, "367155": 10, "4": [3, 44], "42": 20, "5": 3, "6": 3, "7": 3, "8": 14, "9": 49, "A": 8, "For": 9, "If": [45, 46, 48, 49], "No": 48, "Or": 49, "The": [45, 46], "To": 49, "__init__": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 44, 46], "abc": [4, 5, 8, 9, 10], "abort": 45, "about": 48, "abstract": [4, 5, 8, 9, 10, 48], "accept": 8, "actual": 48, "add": [2, 8, 9, 10], "add_prefix_spac": 10, "add_special_token": [2, 3, 15], "aim": 48, "algorithm": 48, "align": [2, 8], "all": [3, 49], "allow": 48, "amazon_review": [13, 17], "amazonreviewfulldataset": [0, 13, 17, 18, 47], "an": [44, 45, 46, 48], "ani": [2, 9, 45, 46], "anyon": 48, "append": [2, 8], "appli": 8, "ar": [48, 49], "architectur": 48, "archiv": 45, "archive_file_path": 45, "around": 48, "arrai": [0, 13], "arraydatasetconfig": [0, 13, 14], "arraytextdataset": [0, 13, 14], "attention_mask": 9, "backbon": 48, "banhxeo": 49, "base": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 18, 19, 20, 23, 44, 45, 46], "base_dataset": 14, "basetextdataset": [0, 13, 14, 15, 18, 19], "basic": 48, "batch": 9, "batch_decod": [1, 2], "batch_encod": [1, 2], "batch_id": 2, "batch_siz": [14, 20], "believ": 48, "bert": 9, "bertpostprocessor": [1, 2, 9], "between": 46, "black": 48, "blob": [8, 10], "bo": [1, 3, 9, 11], "bool": [2, 3, 5, 6, 7, 8, 10, 13, 14, 15, 20], "bos_tok": [1, 2, 3, 11], "box": 48, "bpe": [2, 5], "bpemodel": [2, 5, 6], "build": [48, 49], "built": 48, "byteleveldecod": [1, 2, 4], "bytelevelpretoken": [1, 2, 10], "bytes_to_unicod": [1, 2, 10], "callabl": 8, "callback": 40, "can": [48, 49], "cannot": 48, "cd": 49, "change_fn": 8, "charact": 8, "check": [45, 46], "check_and_rais": [44, 46], "check_md5": [0, 44, 45], "checksum": 45, "choos": 46, "cl": [1, 3, 9, 11], "clariti": 48, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 19, 20, 44, 46], "classic": 23, "classif": 48, "classmethod": [2, 5, 6, 7, 8, 13, 15], "clean": 48, "clone": 49, "close": 48, "cls_tok": [1, 2, 3, 11], "code": 48, "codebas": 48, "colab": [0, 44, 46], "com": [8, 10, 49], "come": 48, "compon": 48, "concept": 48, "condit": 46, "config": [1, 2, 5, 6, 7, 9, 13, 14, 15, 23, 32, 40], "config_cl": 44, "configur": [3, 48], "continu": 45, "convent": 3, "cook": 48, "core": [0, 14, 47, 48, 49], "corpu": [2, 5, 6, 7], "count": 48, "cov": 49, "creat": 48, "crispi": 48, "curiou": 48, "current": 49, "data": [0, 45, 47, 49], "dataload": [0, 13, 20], "dataset": [0, 13, 20, 45, 49], "dataset_base_path": 45, "datasetconfig": [0, 13, 15], "datasetsplit": [0, 13, 15], "debug": [44, 46], "decent": 48, "decod": [1, 2], "delici": 48, "delight": 48, "depend": 48, "design": 48, "detoken": [2, 5, 6, 7], "dict": [2, 3, 6, 9, 14, 15, 45], "dictionari": 9, "direct": [8, 45], "directori": 45, "dirti": 48, "discard": 8, "dive": 48, "do_not_pad": [3, 15], "doc": 49, "document": 49, "doe": [45, 48], "download": [13, 15, 45, 49], "download_arch": [0, 44, 45], "downloaddatasetfil": [0, 13, 15], "drive": [45, 49], "drop_last": [14, 20], "dropout": 6, "e": 45, "eat": 48, "educ": 48, "effici": 48, "einop": 49, "encod": [1, 2, 10], "encode_config": [13, 14], "encourag": 48, "end": 8, "enough": 48, "ensur": 48, "enum": 44, "enumer": 44, "environ": 49, "eo": [1, 3, 9, 11], "eos_tok": [1, 2, 3, 11], "error": [44, 46], "error_typ": 46, "especi": 48, "even": 48, "ever": 48, "exactli": 48, "exampl": 9, "except": [44, 45, 46], "expect": 45, "experi": 48, "explicit": 48, "ext": [13, 15, 45], "extens": 45, "extra": 49, "extract": 45, "extract_arch": [0, 44, 45], "extracted_data_dir_path": 45, "face": 49, "factori": 14, "failur": 45, "fals": [3, 6, 8, 14, 15, 46], "file": [0, 44], "file_info": [13, 15], "fileter_fn": 8, "filter": [2, 8], "filter_fn": 8, "float": 6, "follow": 49, "foundat": 48, "from": [8, 10, 45, 48, 49], "from_config": [2, 5, 6, 7], "from_pretrain": [1, 2], "from_str": [2, 8], "function": 8, "fundament": 48, "further": 10, "g": 45, "gdown": [45, 49], "generalpostprocessor": [1, 2, 9], "genuin": 48, "get": [13, 14], "get_all_text": [13, 15], "get_data": [13, 15], "get_pair_stat": [2, 5, 6], "get_runtim": [0, 44, 47], "git": 49, "github": [8, 10, 49], "given": 45, "go": 48, "goal": 48, "googl": [45, 49], "gpt": [9, 10], "gpt2": [23, 32], "gptpostprocessor": [1, 2, 9], "gpttoken": [0, 1, 2, 11, 47], "gpu": 48, "gram": 48, "gru": [23, 25], "gz": 45, "hand": 48, "have": 48, "heart": 48, "here": 48, "hf": 49, "hf_load_kwarg": [13, 15], "hf_name": [13, 15], "hf_path": [13, 15], "hfdataset": [0, 13, 15, 47], "high": 48, "hood": 48, "how": [9, 48], "http": [8, 10, 49], "hug": 49, "huggingfac": 8, "i": [8, 45, 46, 48], "id": [2, 3], "imdb": [13, 17], "imdbdataset": [0, 13, 17, 19, 47], "implement": [9, 48], "includ": 49, "index": [14, 48], "info": [44, 46], "ingredi": 48, "initi": 46, "input_id": 9, "insid": 48, "instal": 48, "instanc": 46, "int": [2, 3, 5, 6, 7, 8, 9, 13, 14, 15, 18, 19, 20], "intuit": 48, "ipython": [0, 44], "is_classif": [13, 14, 15], "is_train": 6, "iter": [2, 5, 6, 7, 14], "its": 48, "jax": [2, 14, 15], "jaxtyp": 49, "jupyt": [0, 44], "just": 48, "kei": 48, "kept": 8, "kitchen": 48, "kwarg": [2, 4, 5, 6, 7, 14, 20, 44], "l844": 8, "label": [13, 15], "label_column": [13, 15], "label_map": [13, 14, 15], "languag": 48, "larg": 48, "layer": [23, 32, 48], "layer_norm": [32, 35], "learn": 48, "learner": 48, "left": [3, 15], "level": [46, 48], "leverag": 48, "librari": [8, 48], "like": 48, "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 15], "liter": [2, 3, 14, 15], "llm": 23, "load": [0, 13, 15], "load_json": [0, 44, 45], "loader": [0, 13], "local": 45, "log": [0, 44, 45], "logger": [0, 44, 46], "longest": [3, 15], "lowercasenorm": [1, 2, 8], "lstm": [23, 25], "make": 48, "manag": [48, 49], "mani": 48, "manipul": 49, "mask": [1, 3, 11], "mask_tok": [1, 2, 3, 11], "master": 10, "match": 45, "max_length": [2, 3, 15], "md5": [13, 15, 45], "merge_pair": [2, 5, 6], "messag": 46, "met": 46, "method": 9, "minim": 48, "mlp": [23, 25, 48], "model": [1, 2, 48], "modif": 8, "modifi": 48, "modul": [0, 1, 2, 5, 13, 17, 23, 25, 32, 35, 38, 40, 44, 48], "modular": 48, "more": [48, 49], "msg": 46, "n": 48, "n_gram": [23, 38], "naivedataload": [0, 13, 20], "name": [13, 15, 45], "namesak": 48, "natur": 48, "neg": 15, "network": 48, "neural": [23, 48], "never": 48, "new": 10, "nfcnormal": [1, 2, 8], "nlp": 48, "nltk": 49, "nltkdecod": [1, 2, 4], "nltkpretoken": [1, 2, 10], "nltktoken": [0, 1, 2, 11, 47], "none": [2, 3, 6, 8, 10, 13, 14, 15, 18, 19, 45], "normal": [1, 2, 10], "normalizedstr": [1, 2, 8, 10], "np": [2, 14, 15], "num_work": [14, 20], "numpi": 49, "object": [2, 3, 8, 10, 14, 15, 20, 46], "offset": [2, 3], "old": 23, "ones": 49, "openai": 10, "option": [3, 10, 14, 45, 49], "order": 3, "origin": [2, 8], "original_shift": [2, 8], "other": [45, 48], "our": 48, "own": 48, "packag": [47, 48], "pad": [1, 2, 3, 11, 15], "pad_tok": [1, 2, 3, 11], "padding_sid": [2, 3, 15], "page": 48, "pair_to_merg": 6, "pancak": 48, "paramet": [8, 45, 46], "path": [2, 45], "pattern": 10, "perform": 48, "pillar": 48, "pip": 49, "place": 6, "plotli": 49, "po": 15, "polar": 49, "post_processor": [1, 2], "postprocessor": [1, 2, 9], "practic": 48, "pre_token": [1, 2], "pre_tokenized_str": [5, 6, 7], "prepend": [2, 8], "preset": [1, 2], "pretoken": [1, 2, 10], "pretokenizedstr": [1, 2, 5, 6, 7, 9, 10], "primari": 48, "printlogg": [0, 44, 46], "process": [2, 9, 48], "process_batch": [2, 9], "process_token": [2, 9], "processconfig": [1, 2, 3, 9, 14], "product": 48, "progress": [2, 5, 6, 7], "project": 48, "prompt": 45, "properti": 3, "provid": [45, 48], "punctuat": 10, "punctuationpretoken": [1, 2, 10], "py": 10, "pydant": 49, "pytest": 49, "python": [48, 49], "pytorch": [48, 49], "question": 10, "r": 8, "rais": [45, 46], "re": 48, "reason": 48, "recip": 48, "recommend": 49, "refer": [8, 10], "regexpretoken": [1, 2, 10], "relianc": 48, "request": 45, "requir": 49, "resv": [1, 3, 11], "resv_tok": [1, 2, 3, 11], "return": [3, 8, 10], "return_tensor": [2, 13, 14, 15], "revolv": 48, "rich": 49, "right": [3, 15], "rnn": [23, 25], "root_dir": [13, 15, 18, 19], "rtd": 49, "run": 48, "runtimeenv": [0, 44, 47], "save": 45, "savori": 48, "scratch": 48, "search": 48, "see": 48, "seed": [13, 14, 15, 18, 19, 20], "sep": [1, 3, 9, 11], "sep_tok": [1, 2, 3, 11], "sequenc": [8, 10], "sequencenorm": [1, 2, 8], "sequencepretoken": [1, 2, 10], "shell": [0, 44], "should": [8, 9], "shuffl": [14, 20], "shutil": 45, "simpl": 48, "simpletoken": [1, 2, 11], "simplic": 48, "singl": 4, "slice": [2, 8], "small": 48, "so": 48, "some": 48, "sourc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 19, 20, 44, 45, 46, 49], "special": [3, 9], "special_token": [1, 2, 3, 6, 7, 9, 11], "special_token_idx": [2, 3], "specialtoken": [1, 2, 3, 6, 7, 9, 11], "speed": 48, "sphinx": 49, "split": [1, 2, 10, 13, 15], "split_nam": [13, 15, 18, 19], "src": [8, 10], "stackoverflow": 10, "standard": 46, "start": 8, "step": 8, "str": [2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 18, 19, 45, 46], "strict": 49, "string": [4, 10], "strip_left": 8, "strip_right": 8, "stripnorm": [1, 2, 8], "strive": 48, "style": 9, "submodul": [0, 1, 47], "subpackag": [47, 48], "support": 45, "sync": 49, "take": 10, "taken": 10, "tar": 45, "tarfil": 45, "target": 45, "templat": [44, 46], "tensor": 49, "test": [13, 15, 49], "text": [2, 13, 15, 48], "text_column": [13, 15], "theme": 49, "thi": [8, 48], "thing": 48, "think": 48, "three": 48, "to_arrai": [13, 15], "to_load": [13, 14], "token": [0, 1, 13, 14, 15, 48], "token_id": [2, 5, 6, 7, 9], "tokenized_str": 9, "tokenizermodel": [1, 2, 5, 6, 7], "tool": 48, "tqdm": 49, "train": [1, 2, 5, 6, 7, 13, 15, 18, 19, 48], "trainer": 40, "transform": [2, 8], "transpar": 48, "true": [2, 3, 5, 6, 7, 8, 10, 13, 14, 15, 20], "truncat": [2, 3, 15], "truncation_sid": [2, 3, 15], "tupl": [3, 6, 8], "turn": 9, "type": [14, 45, 46, 49], "under": 48, "understand": 48, "union": 3, "unk": [1, 3, 11], "unk_tok": [1, 2, 3, 11], "up": 48, "url": [13, 15, 45], "urllib": 45, "us": [6, 48, 49], "user": 45, "util": [0, 47, 48], "uv": 49, "v0": 8, "val": [13, 15], "validate_config": [0, 44, 47], "valu": [2, 3, 44], "valueerror": 45, "variou": 48, "ve": 48, "version": 9, "via": 49, "vietfood": 49, "vietnames": 48, "vocabulari": 48, "want": 49, "warn": [44, 46], "we": [9, 48, 49], "what": 48, "where": 45, "while": 48, "whitespacedecod": [1, 2, 4], "whitespacepretoken": [1, 2, 10], "wonder": 48, "word": [2, 5, 10], "word2vec": [23, 25], "word_freq": 6, "wordlevelmodel": [2, 5, 7], "work": 48, "xet": 49, "you": [48, 49], "your": 48, "zip": 45, "zipfil": 45}, "titles": ["banhxeo package", "banhxeo.core package", "banhxeo.core.tokenizer package", "banhxeo.core.tokenizer.config module", "banhxeo.core.tokenizer.decoder package", "banhxeo.core.tokenizer.model package", "banhxeo.core.tokenizer.model.bpe module", "banhxeo.core.tokenizer.model.word module", "banhxeo.core.tokenizer.normalizers package", "banhxeo.core.tokenizer.post_processor package", "banhxeo.core.tokenizer.pre_tokenizer package", "banhxeo.core.tokenizer.presets module", "banhxeo.core.vocabulary module", "banhxeo.data package", "banhxeo.data.array module", "banhxeo.data.base module", "banhxeo.data.config module", "banhxeo.data.dataset package", "banhxeo.data.dataset.amazon_review module", "banhxeo.data.dataset.imdb module", "banhxeo.data.loader module", "banhxeo.data.torch module", "banhxeo.data.transforms module", "banhxeo.model package", "banhxeo.model.base module", "banhxeo.model.classic package", "banhxeo.model.classic.gru module", "banhxeo.model.classic.lstm module", "banhxeo.model.classic.mlp module", "banhxeo.model.classic.rnn module", "banhxeo.model.classic.word2vec module", "banhxeo.model.config module", "banhxeo.model.llm package", "banhxeo.model.llm.config module", "banhxeo.model.llm.gpt2 module", "banhxeo.model.llm.layers package", "banhxeo.model.llm.layers.layer_norm module", "banhxeo.model.neural module", "banhxeo.model.old package", "banhxeo.model.old.n_gram module", "banhxeo.train package", "banhxeo.train.callbacks module", "banhxeo.train.config module", "banhxeo.train.trainer module", "banhxeo.utils package", "banhxeo.utils.file module", "banhxeo.utils.logging module", "banhxeo", "Welcome to Banhxeo\u2019s Documentation!", "Installation", "&lt;no title&gt;"], "titleterms": {"": 48, "amazon_review": 18, "api": 48, "arrai": 14, "banhxeo": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "base": [15, 24], "bpe": 6, "callback": 41, "classic": [25, 26, 27, 28, 29, 30], "config": [3, 16, 31, 33, 42], "core": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "dataset": [17, 18, 19], "decod": 4, "depend": 49, "document": 48, "file": 45, "get": 48, "gpt2": 34, "gru": 26, "imdb": 19, "indic": 48, "instal": 49, "layer": [35, 36], "layer_norm": 36, "llm": [32, 33, 34, 35, 36], "loader": 20, "log": 46, "lstm": 27, "mlp": 28, "model": [5, 6, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "modul": [3, 6, 7, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 41, 42, 43, 45, 46], "n_gram": 39, "neural": 37, "normal": 8, "old": [38, 39], "packag": [0, 1, 2, 4, 5, 8, 9, 10, 13, 17, 23, 25, 32, 35, 38, 40, 44], "philosophi": 48, "post_processor": 9, "pre_token": 10, "preset": 11, "refer": 48, "rnn": 29, "start": 48, "submodul": [2, 5, 13, 17, 23, 25, 32, 35, 38, 40, 44], "subpackag": [0, 1, 2, 13, 23, 32], "tabl": 48, "token": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "torch": 21, "train": [40, 41, 42, 43], "trainer": 43, "transform": 22, "util": [44, 45, 46], "vocabulari": 12, "welcom": 48, "word": 7, "word2vec": 30}})