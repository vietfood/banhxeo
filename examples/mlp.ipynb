{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "from banhxeo import trainer\n",
    "from banhxeo.core import NLTKTokenizer\n",
    "from banhxeo.data import IMDBDataset\n",
    "from banhxeo.model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97e227",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da5617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = IMDBDataset(\"dataset\", split_name=\"train\", seed=SEED)\n",
    "imdb_test = IMDBDataset(\"dataset\", split_name=\"test\", seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512a73e",
   "metadata": {},
   "source": [
    "### Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = NLTKTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a37756",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(\n",
    "    corpus=(imdb_train.get_all_texts() + imdb_test.get_all_texts()), progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818b147",
   "metadata": {},
   "source": [
    "### Load Array Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"return_tensors\": \"jax\",\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"truncation\": True,\n",
    "    \"padding\": \"max_length\",\n",
    "    \"padding_side\": \"left\",\n",
    "    \"add_special_tokens\": True,\n",
    "    \"is_classification\": True,\n",
    "    \"label_map\": {\"pos\": 1, \"neg\": 0},\n",
    "}\n",
    "\n",
    "train_set = imdb_train.to_array(**args_dict)\n",
    "test_set = imdb_test.to_array(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to DataLoader\n",
    "train_loader = train_set.to_loader(\n",
    "    batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, seed=SEED\n",
    ")\n",
    "test_loader = test_set.to_loader(\n",
    "    batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4, seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd25db7",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef08563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    output_size=1,\n",
    "    pad_id=tokenizer.special_tokens.pad_id,\n",
    "    hidden_sizes=[512, 256],\n",
    "    embedding_dim=512,\n",
    "    activation_fn=\"relu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random key\n",
    "key = jax.random.key(SEED)\n",
    "key, params_key, dropout_key = jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a80957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "dummy_input_ids = jnp.ones((BATCH_SIZE, MAX_LENGTH), dtype=jnp.int32)\n",
    "dummy_attention_mask = jnp.ones((BATCH_SIZE, MAX_LENGTH), dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ce4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model parameters\n",
    "params = model.init(\n",
    "    params_key, \n",
    "    input_ids=dummy_input_ids, \n",
    "    attention_mask=dummy_attention_mask,\n",
    "    dropout=True\n",
    ")['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optax.adamw(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b289da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TrainState\n",
    "state = trainer.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimizer,\n",
    "    rng=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: trainer.TrainState, batch):\n",
    "    def loss_fn(params):\n",
    "        # Get model predictions\n",
    "        logits = state.apply_fn(\n",
    "            {'params': params}, \n",
    "            input_ids=batch['input_ids'], \n",
    "            attention_mask=batch['attention_mask'],\n",
    "            dropout=True, # Enable dropout\n",
    "            rngs={'dropout': state.rng} # Pass the dropout PRNG\n",
    "        )\n",
    "\n",
    "        # Calculate cross-entropy loss\n",
    "        one_hot_labels = jax.nn.one_hot(batch['labels'], num_classes=logits.shape[-1])\n",
    "\n",
    "        # Then use binary cross entropy to calculate loss\n",
    "        loss = optax.sigmoid_binary_cross_entropy(logits, one_hot_labels).mean()\n",
    "        \n",
    "        return loss, logits\n",
    "\n",
    "    # Calculate gradients and loss\n",
    "    (loss, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    \n",
    "    # Update the model state (parameters and optimizer state)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['labels'])\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    # Get model predictions\n",
    "    logits = state.apply_fn(\n",
    "        {'params': state.params}, \n",
    "        input_ids=batch['input_ids'], \n",
    "        attention_mask=batch['attention_mask'],\n",
    "        dropout=False # Disable dropout for evaluation\n",
    "    )\n",
    "    \n",
    "    one_hot_labels = jax.nn.one_hot(batch['labels'], num_classes=logits.shape[-1])\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, one_hot_labels).mean()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['labels'])\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in (pbar := tqdm(range(EPOCHS), desc=\"Training\")):\n",
    "    # Training phase\n",
    "    train_loss, train_accuracy = [], []\n",
    "    for batch in train_loader:\n",
    "        # Perform one training step\n",
    "        state, metrics = train_step(state, batch) # type: ignore\n",
    "        \n",
    "        train_loss.append(metrics['loss'])\n",
    "        train_accuracy.append(metrics['accuracy'])\n",
    "\n",
    "    # Evaluate phase\n",
    "    test_loss, test_accuracy = [], []\n",
    "    for batch in test_loader:\n",
    "        metrics = eval_step(state, batch) # type: ignore\n",
    "\n",
    "        test_loss.append(metrics['loss'])\n",
    "        test_accuracy.append(metrics['accuracy'])\n",
    "        \n",
    "    # Log results for the epoch\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_train_acc = np.mean(train_accuracy)\n",
    "    avg_test_loss = np.mean(test_loss)\n",
    "    avg_test_acc = np.mean(test_accuracy)\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        {\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train Acc\": avg_train_acc,\n",
    "            \"Test Loss\": avg_test_loss,\n",
    "            \"Test Acc\": avg_test_acc\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banhxeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
