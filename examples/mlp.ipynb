{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d244027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "from banhxeo import trainer\n",
    "from banhxeo.core import NLTKTokenizer\n",
    "from banhxeo.data import IMDBDataset\n",
    "from banhxeo.model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9382ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97e227",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da5617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27babaa0723b40f8bdbbac04e90b2f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/12.5k [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f08e130d5040e698dd82506b01c3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/12.5k [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a02c0d5af6401a85b06a99311faff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/12.5k [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce481afcaf9e4a7b960bbe88d1fe1abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/12.5k [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_train = IMDBDataset(\"dataset\", split_name=\"train\", seed=SEED)\n",
    "imdb_test = IMDBDataset(\"dataset\", split_name=\"test\", seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9401b61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1514',\n",
       " 'rating': 7,\n",
       " 'content': \"Lucio Fulci's Cat in the Brain is an inventive and somewhat egotistical tale of a director's decent into madness. The director in question is Fulci himself, who stars in the film. Fulci has become known to horror fans everywhere as 'the godfather of gore', and for good reason, as he has provided us with some of the nastiest and most gruesome films ever to grace the silver screen; from the eyeball violence in films like 'Zombi 2', to a man been hacked to death with chains in 'The Beyond', all the way to the full on gore fest known as 'The New York Ripper'; if you want gore (and let's face it, who doesn't), Fulci is your man. However, all this catering for gorehounds like you and I has taken its toll on Fulci's mental state, and he's quickly delving into madness, brought about by what he films. Fulci's problems don't end at his mental state either, as his psychiatrist that he has gone to see about his problem has took it upon himself to take up murder as a hobby, using Fulci's films as blueprints for the murders!<br /><br />I've got to say, the acting in this film is absolutely atrocious. There is one scene in particular that involves a hooker, and it's only fit to be laughed at, for both it's acting and it's stupidity. Fulci takes the lead role of the film (obviously). He's not an actor, and it shows, but his performance is actually the best in the film. It's even safe to say that one the whole, the acting is bad for an Italian horror film. Of course, nobody goes into an Italian horror expecting good acting, so it's somewhat forgivable, but I do think that Fulci could have hired some better ones. Bad dubbing doesn't exactly help either. However, something that does help is the fact that the terrible acting is counterbalanced by lots of gore, and it's extreme to say the least! People get their heads cut off, a woman is slain in the shower (and unlike Psycho, here we REALLY see it), people are hacked up, fed to pigs and there's lots and lots of cinema's finest melee weapon - the chainsaw on display, which delighted me no end. The amount of gore is massively over the top a lot of the time, which gives the film something of a 'spoof' feel, but Cat in the Brain is obviously a tongue in cheek film anyway.<br /><br />It would be hard to make a film about yourself and not come across as being a bit of a big head, and Fulci does indeed come across as a bit of a big head in this movie. His name is mentioned often, and he's on screen nearly all the time; it's not too much unlike 'New Nightmare' in the ego stakes, but it's obvious he had a good time making this, and I for one had fun watching it, so we can forgive him a little egotism. The film's ending lets it down - I saw it coming a mile off, but then didn't seriously think that the movie would take that route, but I was wrong; it did, unfortunately. The ending left me cold, and the film is a better watch if you turn it off just before the final two minutes. However, despite it's ending and terrible acting, Cat in the Brain is a lot of fun and will please Fulci enthusiasts no end, and it is therefore recommended.\",\n",
       " 'label': 'pos'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0f852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7430',\n",
       " 'rating': 10,\n",
       " 'content': 'Personnaly I really loved this movie, and it particularly moved me. The two main actors are giving us such great performances, that at the end, it is really heart breaking to know what finally happened to their characters.<br /><br />The alchemy between Barbra Streisand and Kris Kristofferson is marvelous, and the song are just great the way they are. <br /><br />That\\'s why I didn\\'t feel surprised when I learned it had won 5 golden globe awards (the most rewarded movie at the Golden Globes), an Oscar and even a Grammy. This movie is a classic that deserves to be seen by anyone. A great movie, that has often been criticized (maybe because Streisand dared to get involved in it, surely as a \"co-director\"). Her artistry is the biggest, and that will surely please you!',\n",
       " 'label': 'pos'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512a73e",
   "metadata": {},
   "source": [
    "### Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad41dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = NLTKTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a37756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4e87f5b7d34228a1ecdd0b569f51b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-tokenizing text:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc57fdb7f744831b6daadf71a196d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Add word to vocabulary:   0%|          | 0/222115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.train(\n",
    "    corpus=(imdb_train.get_all_texts() + imdb_test.get_all_texts()), progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818b147",
   "metadata": {},
   "source": [
    "### Load Array Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf13ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"return_tensors\": \"jax\",\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"truncation\": True,\n",
    "    \"padding\": \"max_length\",\n",
    "    \"padding_side\": \"left\",\n",
    "    \"add_special_tokens\": True,\n",
    "    \"is_classification\": True,\n",
    "    \"label_map\": {\"pos\": 1, \"neg\": 0},\n",
    "}\n",
    "\n",
    "train_set = imdb_train.to_array(**args_dict)\n",
    "test_set = imdb_test.to_array(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e410b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to DataLoader\n",
    "train_loader = train_set.to_loader(\n",
    "    batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, seed=SEED\n",
    ")\n",
    "test_loader = test_set.to_loader(\n",
    "    batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4, seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd25db7",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef08563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    output_size=1,\n",
    "    pad_id=tokenizer.special_tokens.pad_id,\n",
    "    hidden_sizes=[512, 256],\n",
    "    embedding_dim=512,\n",
    "    activation_fn=\"relu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214a00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "    # attributes\n",
      "    vocab_size = 222123\n",
      "    output_size = 1\n",
      "    embedding_dim = 512\n",
      "    hidden_sizes = [512, 256]\n",
      "    pad_id = 0\n",
      "    activation_fn = 'relu'\n",
      "    dropout_rate = 0.0\n",
      "    aggregate_strategy = 'mean'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becf747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random key\n",
    "key = jax.random.key(SEED)\n",
    "key, params_key, dropout_key = jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a80957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "dummy_input_ids = jnp.ones((BATCH_SIZE, MAX_LENGTH), dtype=jnp.int32)\n",
    "dummy_attention_mask = jnp.ones((BATCH_SIZE, MAX_LENGTH), dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198ce4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model parameters\n",
    "params = model.init(\n",
    "    params_key, \n",
    "    input_ids=dummy_input_ids, \n",
    "    attention_mask=dummy_attention_mask,\n",
    "    dropout=True\n",
    ")['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216e3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optax.adamw(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b289da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TrainState\n",
    "state = trainer.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimizer,\n",
    "    rng=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec57dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: trainer.TrainState, batch):\n",
    "    def loss_fn(params):\n",
    "        # Get model predictions\n",
    "        logits = state.apply_fn(\n",
    "            {'params': params}, \n",
    "            input_ids=batch['input_ids'], \n",
    "            attention_mask=batch['attention_mask'],\n",
    "            dropout=True, # Enable dropout\n",
    "            rngs={'dropout': state.rng} # Pass the dropout PRNG\n",
    "        )\n",
    "\n",
    "        # Calculate cross-entropy loss\n",
    "        one_hot_labels = jax.nn.one_hot(batch['labels'], num_classes=logits.shape[-1])\n",
    "\n",
    "        # Then use binary cross entropy to calculate loss\n",
    "        loss = optax.sigmoid_binary_cross_entropy(logits, one_hot_labels).mean()\n",
    "        \n",
    "        return loss, logits\n",
    "\n",
    "    # Calculate gradients and loss\n",
    "    (loss, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    \n",
    "    # Update the model state (parameters and optimizer state)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['labels'])\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530b0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    # Get model predictions\n",
    "    logits = state.apply_fn(\n",
    "        {'params': state.params}, \n",
    "        input_ids=batch['input_ids'], \n",
    "        attention_mask=batch['attention_mask'],\n",
    "        dropout=False # Disable dropout for evaluation\n",
    "    )\n",
    "    \n",
    "    one_hot_labels = jax.nn.one_hot(batch['labels'], num_classes=logits.shape[-1])\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, one_hot_labels).mean()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch['labels'])\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4754268dc4674b878daaf91de0cae2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in (pbar := tqdm(range(EPOCHS), desc=\"Training\")):\n",
    "    # Training phase\n",
    "    train_loss, train_accuracy = [], []\n",
    "    for batch in train_loader:\n",
    "        # Perform one training step\n",
    "        state, metrics = train_step(state, batch) # type: ignore\n",
    "        \n",
    "        train_loss.append(metrics['loss'])\n",
    "        train_accuracy.append(metrics['accuracy'])\n",
    "\n",
    "    # Evaluate phase\n",
    "    test_loss, test_accuracy = [], []\n",
    "    for batch in test_loader:\n",
    "        metrics = eval_step(state, batch) # type: ignore\n",
    "\n",
    "        test_loss.append(metrics['loss'])\n",
    "        test_accuracy.append(metrics['accuracy'])\n",
    "        \n",
    "    # Log results for the epoch\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_train_acc = np.mean(train_accuracy)\n",
    "    avg_test_loss = np.mean(test_loss)\n",
    "    avg_test_acc = np.mean(test_accuracy)\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        {\n",
    "            \"Train Loss\": avg_train_loss,\n",
    "            \"Train Acc\": avg_train_acc,\n",
    "            \"Test Loss\": avg_test_loss,\n",
    "            \"Test Acc\": avg_test_acc\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banhxeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
